{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bijlage 2 - Code chlorofyl A en chemicaliÃ«n\n",
    "Deze bijlage bevat alle code, uitgezonderd die van de tijdreeks, die gerelateerd is aan het deel van het onderzoek over chlorofyl A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Databewerking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read datafile\n",
    "df = pd.read_csv('../data/data_clean.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of parameters to be removed - kept in seperate file for convenience\n",
    "remove_pars = pd.read_csv('../data/remove_cols.csv', header=None)\n",
    "remove_pars_list = remove_pars[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overwrite datafile with filtered version, then fix PAR column for our purposes\n",
    "df = df[~df.PAR.isin(remove_pars_list)]\n",
    "df['PAR'] = df['PAR'] + ' ' + df['EHD'] + ' ' + df['HDH']\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "#Repair broken datetime field\n",
    "df.DATETIME = pd.to_datetime(df.DATETIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ontwikkeling Chlorofyl A in Nederland**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframe that only contains chlf-A, and remove one location that has too much influence on the trend\n",
    "chlf_ts = df[(df.PAR == 'CHLFa ug/l NVT') & (df.BGC != '<') & (df.LOC != 'STEILBK')][['DATETIME', 'WAARDE']]\n",
    "chlf_ts['DATETIME'] = pd.to_datetime(chlf_ts['DATETIME'])\n",
    "chlf_ts.index = chlf_ts.DATETIME\n",
    "chlf_ts.drop(columns=['DATETIME'], inplace=True)\n",
    "\n",
    "#Resample with monthly means - we need equal spacing for time series, after all. \n",
    "chlf_ts = chlf_ts.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick overview\n",
    "fig, ax=plt.subplots(figsize=(12,6))\n",
    "chlf_ts.plot(ax=ax, legend=False)\n",
    "ax.set_xlabel(\"Jaartal\", fontweight='bold')\n",
    "ax.set_ylabel(\"Gem. hoeveelheid chlorofyl A\", fontweight='bold')\n",
    "ax.set_title(\"Gemiddelde hoeveelheid chlorofyl A\", fontweight='bold', fontsize=12)\n",
    "ax.yaxis.grid(color='lightgray', linestyle='-', linewidth=0.5 )\n",
    "ax.set_axisbelow(True)\n",
    "plt.savefig('../img/mean_chlfa_unfiltered.png')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the CSV somewhere to load in R for time series\n",
    "chlf_ts.to_csv('../data/chlf_ts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlaties Chlf-A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create pivot table with multi-index\n",
    "df_pivot_pars = df.pivot_table(index=['DATETIME', 'LOC'], values='WAARDE', columns='PAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate correlation matrix\n",
    "correlated_pars = df_pivot_pars.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter relevant correlations\n",
    "chlf_a_corrs = correlated_pars['CHLFa ug/l NVT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep the strongest correlations\n",
    "strong_neg_corrs = chlf_a_corrs.sort_values()[0:15]\n",
    "strong_pos_corrs = chlf_a_corrs.sort_values(ascending=False)[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How often do the chemicals with strong correlations to chlf-A appear in the data?\n",
    "pos_corr_counts = [df_pivot_pars[x].notnull().sum() for x in strong_pos_corrs.index]\n",
    "neg_corr_counts =[df_pivot_pars[x].notnull().sum() for x in strong_neg_corrs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframes with strong/weak corrs and their counts\n",
    "\n",
    "#Positive\n",
    "strong_positive_df = pd.DataFrame({\"Chemical\": strong_pos_corrs.index,\n",
    "                                          \"Correlation\": strong_pos_corrs.values, \n",
    "                                          \"No of Observations\": pos_corr_counts})\n",
    "strong_positive_df.set_index('Chemical', inplace=True)\n",
    "\n",
    "#Negative\n",
    "strong_negative_df = pd.DataFrame({\"Chemical\": strong_neg_corrs.index,\n",
    "                                          \"Correlation\": strong_neg_corrs.values, \n",
    "                                          \"No of Observations\": neg_corr_counts})\n",
    "strong_negative_df.set_index('Chemical', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carbuforan has been found while it really shouldn be - are the concentrations relevant?\n",
    "df[df.PAR == 'cbfrn ug/l NVT'].BGC.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCDD's, PCB's en PCDF's: Dioxines in Nederland**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset of all data that contains dioxins\n",
    "df_dioxins = df[(df.PAR.str.contains('PCB')) | (df.PAR.str.contains('PCDF')) | (df.PAR.str.contains('PCDD'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out all measurements of dioxins that are below the reporting treshold\n",
    "df_dioxins = df_dioxins[df_dioxins.BGC != '<']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repair datetime field\n",
    "df_dioxins['DATETIME'] = pd.to_datetime(df_dioxins['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorise values to make EHD irrelevant\n",
    "quantiles_dioxins = pd.qcut(df_dioxins[df_dioxins.EHD == 'ug/kg'].WAARDE, 5, labels=False)\n",
    "quantiles_dioxins = quantiles_dioxins.append(pd.qcut(df_dioxins[df_dioxins.EHD == 'ug/l'].WAARDE, 5, labels=False))\n",
    "quantiles_dioxins = quantiles_dioxins.append(pd.qcut(df_dioxins[df_dioxins.EHD == 'ng/kg'].WAARDE, 5, labels=False))\n",
    "df_dioxins = pd.concat([df_dioxins, quantiles_dioxins], axis=1)\n",
    "df_dioxins['QUANTILE'] = df_dioxins.iloc[:,-1]\n",
    "df_dioxins.drop(df_dioxins.columns[-2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert df_dioxins to a GeoDataFrame for visualization\n",
    "dioxins_geometry = [Point(xy) for xy in zip(df_dioxins.X_RD, df_dioxins.Y_RD)]\n",
    "dioxins_geo_df = gpd.GeoDataFrame(df_dioxins, geometry=dioxins_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read NL map\n",
    "nl_map = gpd.read_file('../data/shapefiles/2018-Imergis_provinciegrenzen_kustlijn.shp')\n",
    "nl_rivers = gpd.read_file('../data/shapefiles/NL-water-simpel.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function\n",
    "def plot_this_year(year):\n",
    "    '''Takes a year (that is within the Geodataframe, of course) and uses it to visualize locations\n",
    "    where the highest concentrations of dioxins were measured. Annotations will only be placed on locations\n",
    "    with the highest quantile of concentrations.\n",
    "    \n",
    "    Returns the slice of the geo_df that was used in order to make it available for further analysis.'''\n",
    "    #Annotation box props\n",
    "    bbox_properties = dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"k\", lw=2)\n",
    "    \n",
    "    #DF manipulation\n",
    "    geo_df_slice = dioxins_geo_df[dioxins_geo_df.DATETIME.dt.year == year]\n",
    "    quantile_values = pd.DataFrame(geo_df_slice.groupby('LOC').QUANTILE.agg('mean'))\n",
    "    geo_df_slice = geo_df_slice.merge(quantile_values, left_on='LOC', right_index=True)\n",
    "    geo_df_slice['new_quantiles'] = pd.qcut(geo_df_slice.QUANTILE_y, 5, labels=False)\n",
    "    \n",
    "    #Plotting\n",
    "    fig, ax = plt.subplots(figsize=(14,14), subplot_kw={'aspect':'equal'})\n",
    "    ax.set_xlim(0,300000)\n",
    "    ax.set_title(\"Dioxin pollution in quantiles, \" + str(year), fontweight='bold')\n",
    "    ax.set_ylim(300000,650000)\n",
    "    ax.set_axis_off()\n",
    "    nl_map.plot(ax=ax, edgecolor='darkgrey', linewidth=0.3)\n",
    "    nl_rivers.plot(ax=ax, alpha=0.9, color='white')\n",
    "    geo_df_slice.plot(ax=ax, cmap='RdYlGn_r',alpha=0.8, column='new_quantiles', scheme='quantiles', markersize=100)\n",
    "    \n",
    "    #Annotation - manually locates several labels elsewhere on the map. \n",
    "    annotated_locs = []\n",
    "    for i, txt in enumerate(geo_df_slice.LOCOMS.tolist()):        \n",
    "        if geo_df_slice.iloc[i, -1] > 3:\n",
    "            if geo_df_slice.iloc[i, 1] not in annotated_locs:\n",
    "                if (txt == \"Beerkanaal midden\"):\n",
    "                    ax.text(s=txt, \n",
    "                            x=geo_df_slice.iloc[i,-8] - 15000,\n",
    "                            y=geo_df_slice.iloc[i,-7] - 5500, \n",
    "                           fontweight='bold', \n",
    "                           bbox=bbox_properties)\n",
    "                    annotated_locs.append(geo_df_slice.iloc[i, 1])\n",
    "                elif (txt != 'Nieuwegein') & (txt != \"Westzaan (kilometer 13)\"):\n",
    "                    ax.text(s=txt, \n",
    "                            x=geo_df_slice.iloc[i,-8],\n",
    "                            y=geo_df_slice.iloc[i,-7] - 4500, \n",
    "                           fontweight='bold', \n",
    "                           bbox=bbox_properties)\n",
    "                    annotated_locs.append(geo_df_slice.iloc[i, 1])\n",
    "                else:\n",
    "                    ax.text(s=txt, \n",
    "                            x=geo_df_slice.iloc[i,-8],\n",
    "                            y=geo_df_slice.iloc[i,-7] + 3500, \n",
    "                           fontweight='bold', \n",
    "                           bbox=bbox_properties)\n",
    "                    annotated_locs.append(geo_df_slice.iloc[i, 1])\n",
    " \n",
    "                    \n",
    "    return geo_df_slice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual list of interesting locations for later use\n",
    "locs_of_interest = ['Nieuwegein', 'Gouda voorhaven', 'Nederweert', 'Schaar van Ouden Doel', 'Sas van Gent',\n",
    "                   'Haringvlietsluis','Brienenoord (kilometer 996.5)', 'Nieuwersluis', 'Puttershoek', 'Keizersveer',\n",
    "                   'Belfeld boven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dict with the top \"polluted\" locations per year.\n",
    "#Also creates a new dataframe with locations for visualization for later. \n",
    "annotated_locations_yearly = {}\n",
    "quantiled_dioxins_df = pd.DataFrame()\n",
    "\n",
    "#Plot each year, save the figure, and build a special quantiled dataframe while we're at it. \n",
    "for year in dioxins_geo_df.DATETIME.dt.year.unique():\n",
    "    x = plot_this_year(year)\n",
    "    plt.savefig('../img/dioxins_concentration_' + str(year) + '.png')\n",
    "    annotated_locations_yearly.update({year: x[x.new_quantiles > 3].LOCOMS.unique()})\n",
    "    quantiled_dioxins_df = pd.concat([quantiled_dioxins_df, x])\n",
    "    #Suppress output for now\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate a list, where each entry is the quantile for a location in a year\n",
    "quantile_change_locs = []\n",
    "for year in dioxins_geo_df.DATETIME.dt.year.unique():\n",
    "    for loc in locs_of_interest: \n",
    "        quantile_change_locs.append([loc,quantiled_dioxins_df[(quantiled_dioxins_df.DATETIME.dt.year == year) &\n",
    "                            (quantiled_dioxins_df.LOCOMS == loc)].new_quantiles.mean(), year])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert said list to dataframe and pivot for plotting purposes. \n",
    "quantile_change_locs = pd.DataFrame(quantile_change_locs).fillna(0)\n",
    "quantile_change_plottable = quantile_change_locs.pivot_table(index=0, values=1, columns=[2])\n",
    "quantile_change_plottable.index.name=None\n",
    "quantile_change_plottable.columns.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Sort and visualize\n",
    "quantile_change_plottable.sort_values(by=[2016, 2015, 2014], ascending=False, inplace=True)\n",
    "quantile_change_plottable.style.background_gradient(cmap='RdYlGn_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lanthanides**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual list of lanthanides found earlier\n",
    "lanthanide_list = ['Gd mg/kg dg', 'Yb mg/kg dg', 'Er mg/kg dg', 'Tm mg/kg dg', 'Ho mg/kg dg', 'Dy mg/kg dg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DF with just lanthanides\n",
    "df_lanthanides = df[df.PAR.isin(lanthanide_list)]\n",
    "df_lanthanides['DATETIME'] = pd.to_datetime(df_lanthanides['DATETIME'])\n",
    "\n",
    "#Instantiate geo-df\n",
    "lanthanides_geometry = [Point(xy) for xy in zip(df_lanthanides.X_RD, df_lanthanides.Y_RD)]\n",
    "lanthanides_geo_df = gpd.GeoDataFrame(df_lanthanides, geometry=lanthanides_geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Filter DF and set textbox props\n",
    "lanthanides_2016 = lanthanides_geo_df[lanthanides_geo_df.DATETIME.dt.year == 2016]\n",
    "bbox_properties = dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"k\", lw=2)\n",
    "\n",
    "#Plot\n",
    "fig, ax = plt.subplots(figsize=(14,14), subplot_kw={'aspect':'equal'})\n",
    "ax.set_xlim(0,300000)\n",
    "ax.set_ylim(300000,650000)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Hoogste aantal metingen lanthanides in Nederland, 2016\", fontweight='bold')\n",
    "nl_map.plot(ax=ax, edgecolor='darkgrey', linewidth=0.3)\n",
    "nl_rivers.plot(ax=ax, alpha=0.9, color='white')\n",
    "lanthanides_2016.plot(ax=ax, cmap='RdYlGn_r',alpha=0.8, column='WAARDE', markersize=100)\n",
    "\n",
    "#Annotate\n",
    "annotated_locs = []\n",
    "for i, txt in enumerate(lanthanides_2016.LOCOMS.tolist()):        \n",
    "    if lanthanides_2016.iloc[i, 1] not in annotated_locs:\n",
    "        if lanthanides_2016.LOCOMS.value_counts()[txt] > 100:\n",
    "            ax.text(s=txt + ', ' + str(lanthanides_2016.LOCOMS.value_counts()[txt]) + 'x', \n",
    "                    x=lanthanides_2016.iloc[i,-5],\n",
    "                    y=lanthanides_2016.iloc[i,-4] + 4500, \n",
    "                   fontweight='bold', \n",
    "                   bbox=bbox_properties)\n",
    "            annotated_locs.append(lanthanides_2016.iloc[i, 1])\n",
    "            \n",
    "plt.savefig('../img/lanthanides.png')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
